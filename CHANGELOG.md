# In CHANGELOG.md

# Changelog

All notable changes to this project will be documented in this file.

## [2.7.0]

- **Custom SQL Validations:** Authors can supply `custom_sql_tests` in YAML configurations to run bespoke SQL against source and target tables, with automatic equality comparison and dashboard surfacing.
- **Documentation Refresh:** README and sample configuration now highlight custom SQL capabilities and usage patterns.
- **Enterprise Demo Expansion:** Demo datasets now include AI guardrail telemetry and carbon ledgers, complete with custom SQL checks that showcase DataPact‚Äôs full validation matrix at hyper-scale.
- **Dashboard Clarity:** Business impact visuals now scope to the most recent run via job timestamps, and custom SQL results surface sample discrepant rows instead of opaque hashes.

## [2.6.0]

- **Executive ROI Intelligence:** Aggregate task runs into new Delta tables (`exec_run_summary`, `exec_domain_breakdown`, etc.) to power ROI counters, impact heatmaps, and owner accountability views in the autogenerated Lakeview dashboard.
- **Business Metadata Pipeline:** Validation configs now accept domain, owner, priority, SLA, and financial impact metadata which flows into results, dashboards, and Genie datasets for richer storytelling.
- **Demo Revamp:** The enterprise demo configuration ships with curated executive metadata so sample dashboards immediately highlight high-value remediation narratives.
- **Hyper-scale Demo Dataset:** `demo/setup.sql` now generates 5M customers, 25M+ transactions, 12M real-time telemetry events, 15M clickstream sessions, AI feature vectors, and multi-cloud FinOps cost baselines to showcase Databricks-scale validation throughput.
- **Parallelism Insight Dashboards:** Lakeview now surfaces peak concurrent tasks, throughput-per-minute trends, and performance heatmaps powered by new `ds_parallel_kpi` and `ds_parallel_efficiency` datasets.
- **Synthwave Executive Theme:** The autogenerated dashboard adopts a dark, neon-inspired palette with refreshed KPI counters for hyperscale storytelling.
- **Job Cost Widget:** A new widget is added to the run history tab showcasing job run costs over time.

## [2.5.1] - 2025-09-17

- **Fixed Some Precision Issues** Now test results will be more accurate
- **Better Metadata Tracking** Enhanced how metadata is captured so things like job run time and task run time is better reflected
- **Naming Consistency** Renamed some columns and visualizations to maintain consistency accross the repo

## [2.5.0] - 2025-09-15

### ‚ú® Added (New Features)

- **Better Visualizations:** Much better visualizations with 3 tabs for different topics, including job run metrics.
- **New Dashboard Theme:** The dashboard has a new, custom, aesthetic theme that makes it stand out and easy to read.
- **Dashboard Filters:** Now you can filter some of the visualizations based on the test results.

### üêõ Fixed

- Some of the visualiztion results were not coming in properly.
- The filter for the most recent job run was on `run_id`, which is not a reliable indicator of the latest run (it has been switched to `job_start_ts`).

## [2.0.0] - 2025-08-02

### ‚ú® Added (New Features)

- **Automated Observability Dashboard:** DataPact now automatically creates and refreshes a rich, interactive Databricks Lakeview Dashboard for every validation job.
- **KPI Header:** The dashboard includes a high-level summary of total tasks, failed tasks, and the overall success rate for at-a-glance insights.
- **Polished Visualizations:** Charts now include custom axis labels, strategic color-coding (red for failures, green for successes), and a balanced, professional layout.
- The `ensure_dashboard_exists` method was completely refactored to programmatically generate the dashboard payload, ensuring reliability and a polished end-user experience.

### üêõ Fixed

- Resolved a series of critical API errors related to the creation of Lakeview dashboards via the SDK.
- Corrected dashboard layout issues that caused skewed and misaligned visualizations.

## [1.0.0] - 2025-05-20

### ‚ú® Added
- Initial release of the DataPact validation engine.
- Support for Count, Row Hash, Aggregate, and Null validations.
- CLI for running validations and orchestrating Databricks Jobs.
