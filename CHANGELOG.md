# In CHANGELOG.md

# Changelog

All notable changes to this project will be documented in this file.

## [2.8.2]

**Build As Wheel:** DataPact can now be installed as a `.whl` file on a Databricks cluster (or other machine).

## [2.8.1]

- **Single-pass SQL Profiling:** The validation template now derives row counts, per-column null stats, aggregate tolerances, and uniqueness duplicate ratios from shared `source_stats`/`target_stats` CTEs so each table is scanned once per run instead of once per metric, materially reducing Serverless SQL runtime and cost on wide configs.
- **Docs & Tests:** Snapshot fixtures, SQL generation unit tests, and the README were refreshed to describe and validate the streamlined stats pipeline.
- **Runtime Environemnt:** DataPact now detects where it's being run (locally or from a Databricks notebook), and if run from a Databricks notebook it will automatically take the notebook's context for authentication rather than looking for environmental variables or the `~/.databrickscfg` file.

## [2.8.0]

- **Row-Level Filters:** Validation tasks now accept an optional `filter` predicate that scopes row count, PK hash, null, aggregate, and uniqueness tests to a narrow slice without rewriting SQL. The active predicate is captured in `result_payload.applied_filter`.
- **Demo Enhancements:** The enterprise demo configuration highlights multiple filtered tasks (recent signups, high-value financial transactions, hazmat shipments, and rolling IoT telemetry) so new users have turnkey examples.
- **Documentation & Samples:** README, sample configs, and changelog document the new filter behavior, and dedicated unit tests cover SQL generation plus validator edge cases.
- **Primary-Key Visibility:** Result payloads now store the configured primary key list and the Historical Validation Runs widget displays it, so you can match PKs to tables without revisiting the YAML config.
- **CLI Quality-of-Life:** Added `datapact plan`, `datapact run --dry-run`, and `datapact init` for scaffolding starter configs and previewing validation plans without provisioning Databricks resources.
- **Platform Compatibility:** Raised the supported floor to Python 3.11, bumped the Databricks SDK requirement to 0.73.0, regenerated `requirements.txt`, and updated CI to install via `pip install -e ".[dev]"` while linting with Ruff and type-checking via mypy.
- **Runtime Safety:** Databricks job polling now uses capped exponential backoff and raises on any non-success result, while `datapact.__version__` exposes the package version for downstream tooling.
- **SQL & Dashboard Hardening:** Fully-qualified table names are parsed/escaped via shared helpers, dashboard/widget structures use TypedDicts, and README/CHANGELOG documentation reflects the new flows so behavior is transparent to operators.

## [2.7.0]

- **Custom SQL Validations:** Authors can supply `custom_sql_tests` in YAML configurations to run bespoke SQL against source and target tables, with automatic equality comparison and dashboard surfacing.
- **Documentation Refresh:** README and sample configuration now highlight custom SQL capabilities and usage patterns.
- **Enterprise Demo Expansion:** Demo datasets now include AI guardrail telemetry and carbon ledgers, complete with custom SQL checks that showcase DataPact‚Äôs full validation matrix at hyper-scale.
- **Dashboard Clarity:** Business impact visuals now scope to the most recent run via job timestamps, and custom SQL results surface sample discrepant rows instead of opaque hashes.

## [2.6.0]

- **Executive ROI Intelligence:** Aggregate task runs into new Delta tables (`exec_run_summary`, `exec_domain_breakdown`, etc.) to power ROI counters, impact heatmaps, and owner accountability views in the autogenerated Lakeview dashboard.
- **Business Metadata Pipeline:** Validation configs now accept domain, owner, priority, SLA, and financial impact metadata which flows into results, dashboards, and Genie datasets for richer storytelling.
- **Demo Revamp:** The enterprise demo configuration ships with curated executive metadata so sample dashboards immediately highlight high-value remediation narratives.
- **Hyper-scale Demo Dataset:** `demo/setup.sql` now generates 5M customers, 25M+ transactions, 12M real-time telemetry events, 15M clickstream sessions, AI feature vectors, and multi-cloud FinOps cost baselines to showcase Databricks-scale validation throughput.
- **Parallelism Insight Dashboards:** Lakeview now surfaces peak concurrent tasks, throughput-per-minute trends, and performance heatmaps powered by new `ds_parallel_kpi` and `ds_parallel_efficiency` datasets.
- **Synthwave Executive Theme:** The autogenerated dashboard adopts a dark, neon-inspired palette with refreshed KPI counters for hyperscale storytelling.
- **Job Cost Widget:** A new widget is added to the run history tab showcasing job run costs over time.

## [2.5.1] - 2025-09-17

- **Fixed Some Precision Issues** Now test results will be more accurate
- **Better Metadata Tracking** Enhanced how metadata is captured so things like job run time and task run time is better reflected
- **Naming Consistency** Renamed some columns and visualizations to maintain consistency across the repo

## [2.5.0] - 2025-09-15

### ‚ú® Added (New Features)

- **Better Visualizations:** Much better visualizations with 3 tabs for different topics, including job run metrics.
- **New Dashboard Theme:** The dashboard has a new, custom, aesthetic theme that makes it stand out and easy to read.
- **Dashboard Filters:** Now you can filter some of the visualizations based on the test results.

### üêõ Fixed

- Some of the visualization results were not coming in properly.
- The filter for the most recent job run was on `run_id`, which is not a reliable indicator of the latest run (it has been switched to `job_start_ts`).

## [2.0.0] - 2025-08-02

### ‚ú® Added (New Features)

- **Automated Observability Dashboard:** DataPact now automatically creates and refreshes a rich, interactive Databricks Lakeview Dashboard for every validation job.
- **KPI Header:** The dashboard includes a high-level summary of total tasks, failed tasks, and the overall success rate for at-a-glance insights.
- **Polished Visualizations:** Charts now include custom axis labels, strategic color-coding (red for failures, green for successes), and a balanced, professional layout.
- The `ensure_dashboard_exists` method was completely refactored to programmatically generate the dashboard payload, ensuring reliability and a polished end-user experience.

### üêõ Fixed

- Resolved a series of critical API errors related to the creation of Lakeview dashboards via the SDK.
- Corrected dashboard layout issues that caused skewed and misaligned visualizations.

## [1.0.0] - 2025-05-20

### ‚ú® Added
- Initial release of the DataPact validation engine.
- Support for Count, Row Hash, Aggregate, and Null validations.
- CLI for running validations and orchestrating Databricks Jobs.
